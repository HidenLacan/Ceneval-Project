import osmnx as ox
import networkx as nx
from networkx.algorithms.community.kernighan_lin import kernighan_lin_bisection
import folium
from shapely.geometry import shape, Polygon
import json
import os
import re
import geopandas as gpd
import requests
import matplotlib.pyplot as plt
from shapely.geometry import Point
#from editor_launcher import launch_polygon_editor,shutdown_server
from pathlib import Path
from osmnx.distance import add_edge_lengths

def sanitize_filename(name: str) -> str:
    return re.sub(r'\W+', '_', name.lower())

def download_bbox(place_name: str):
    print(f"Descargando bounding box de {place_name}...")
    base_cache_dir = Path(__file__).resolve().parent.parent / "cache"
    base_cache_dir.mkdir(parents=True, exist_ok=True)

    cache_file = base_cache_dir / f"{sanitize_filename(place_name)}.json"

    if cache_file.exists():
        with open(cache_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    else:
        url = "https://nominatim.openstreetmap.org/search"
        params = {
            "q": place_name,
            "format": "json",
            "limit": 5,  # Aumentar lÃ­mite para obtener mÃ¡s opciones
            "polygon_geojson": 1,
            "countrycodes": "mx"  # Limitar a MÃ©xico
        }
        headers = {"User-Agent": "mi-aplicacion-ceneval"}
        
        try:
            response = requests.get(url, params=params, headers=headers, timeout=10)
            if response.status_code != 200:
                raise RuntimeError(f"Error en la peticiÃ³n HTTP: {response.status_code}")
            
            data = response.json()
            if not data:
                # Intentar con variaciones del nombre
                variations = [
                    place_name.replace("colonia ", ""),
                    place_name.replace("colonia", ""),
                    place_name + ", MÃ©xico",
                    place_name + ", CDMX"
                ]
                
                for variation in variations:
                    if variation != place_name:
                        print(f"Intentando variaciÃ³n: {variation}")
                        params["q"] = variation
                        response = requests.get(url, params=params, headers=headers, timeout=10)
                        if response.status_code == 200:
                            data = response.json()
                            if data:
                                print(f"Encontrado con variaciÃ³n: {variation}")
                                break
                
                if not data:
                    raise RuntimeError(f"No se encontrÃ³ '{place_name}' en Nominatim. Sugerencias: verifica el nombre, agrega el estado o usa nombres mÃ¡s especÃ­ficos.")
            
            # Usar el primer resultado
            data = [data[0]] if isinstance(data, list) else [data]
            
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2)
            print(f"Guardado en {cache_file}")
                
        except requests.exceptions.Timeout:
            raise RuntimeError(f"Timeout al buscar '{place_name}' en Nominatim. Verifica tu conexiÃ³n a internet.")
        except requests.exceptions.RequestException as e:
            raise RuntimeError(f"Error de conexiÃ³n: {str(e)}")

    return cache_file

def split_graph(G, num_employees=2, algorithm='kernighan_lin'):
    """
    Divide el grafo en zonas segÃºn el nÃºmero de empleados y algoritmo especificado
    - Si num_employees = 1: toda la ruta va a part1
    - Si num_employees >= 2: divide en dos usando el algoritmo especificado
    """
    print("=" * 60)
    print(f"ğŸš€ INICIANDO DIVISIÃ“N DE GRAFO")
    print(f"ğŸ“Š Grafo: {len(G.nodes())} nodos, {len(G.edges())} aristas")
    print(f"ğŸ‘¥ Empleados: {num_employees}")
    print(f"ğŸ”§ Algoritmo solicitado: '{algorithm}'")
    print("=" * 60)
    
    if num_employees == 1:
        # Si solo hay un empleado, asignar toda la ruta
        part1 = set(G.nodes())
        part2 = set()  # VacÃ­o
        print("âœ… MODO UN EMPLEADO: Asignando toda la ruta al empleado Ãºnico")
        print(f"ğŸ“ˆ Resultado: part1={len(part1)} nodos, part2={len(part2)} nodos")
        return part1, part2
    
    print(f"ğŸ”„ MODO MÃšLTIPLES EMPLEADOS: Ejecutando algoritmo '{algorithm}'")
    
    # Algoritmos de divisiÃ³n para mÃºltiples empleados
    if algorithm == 'kernighan_lin' or algorithm == 'current':
        print("ğŸ”¥ EJECUTANDO ALGORITMO KERNIGHAN-LIN REAL")
        part1, part2 = kernighan_lin_bisection(G)
        print(f"âœ… Kernighan-Lin completado: {len(part1)} y {len(part2)} nodos")
    
    elif algorithm == 'kmeans':
        part1, part2 = split_graph_kmeans(G)
    
    elif algorithm == 'voronoi':
        part1, part2 = split_graph_voronoi(G)
    
    elif algorithm == 'random':
        part1, part2 = split_graph_random(G)
    
    elif algorithm == 'dbscan':
        part1, part2 = split_graph_dbscan(G)
    
    elif algorithm == 'spectral':
        part1, part2 = split_graph_spectral(G)
    
    else:
        # Fallback al algoritmo por defecto
        print(f"âš ï¸ ALGORITMO DESCONOCIDO '{algorithm}' - Usando Kernighan-Lin como fallback")
        print("ğŸ”¥ EJECUTANDO ALGORITMO KERNIGHAN-LIN REAL (FALLBACK)")
        part1, part2 = kernighan_lin_bisection(G)
        print(f"âœ… Fallback Kernighan-Lin completado: {len(part1)} y {len(part2)} nodos")
    
    # ValidaciÃ³n final
    total_original = len(G.nodes())
    total_dividido = len(part1) + len(part2)
    if total_original != total_dividido:
        print(f"âŒ ERROR: Nodos perdidos! Original={total_original}, Dividido={total_dividido}")
    else:
        print(f"âœ… VALIDACIÃ“N: Todos los nodos contabilizados ({total_dividido}/{total_original})")
    
    print("=" * 60)
    return part1, part2

def split_graph_kmeans(G):
    """DivisiÃ³n usando K-means clustering en coordenadas de nodos"""
    print("ğŸ”¥ EJECUTANDO ALGORITMO K-MEANS REAL")
    from sklearn.cluster import KMeans
    import numpy as np
    
    # Extraer coordenadas de los nodos
    coords = []
    node_list = list(G.nodes())
    print(f"ğŸ“Š K-means procesando {len(node_list)} nodos")
    
    for node in node_list:
        if 'x' in G.nodes[node] and 'y' in G.nodes[node]:
            coords.append([G.nodes[node]['x'], G.nodes[node]['y']])
        else:
            # Si no hay coordenadas, usar posiciÃ³n por defecto
            coords.append([0, 0])
    
    coords = np.array(coords)
    print(f"ğŸ“ K-means: Coordenadas extraÃ­das, forma: {coords.shape}")
    
    # Aplicar K-means con k=2
    print("ğŸ¯ K-means: Ejecutando clustering con k=2...")
    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
    labels = kmeans.fit_predict(coords)
    
    # Dividir nodos segÃºn las etiquetas
    part1 = set()
    part2 = set()
    
    for i, node in enumerate(node_list):
        if labels[i] == 0:
            part1.add(node)
        else:
            part2.add(node)
    
    print(f"âœ… K-means completado: Cluster 1 = {len(part1)} nodos, Cluster 2 = {len(part2)} nodos")
    print(f"ğŸ“ˆ K-means: Centros = {kmeans.cluster_centers_}")
    
    return part1, part2

def split_graph_voronoi(G):
    """DivisiÃ³n usando diagramas de Voronoi basados en centros de masa"""
    print("ğŸ”¥ EJECUTANDO ALGORITMO VORONOI REAL")
    import numpy as np
    from scipy.spatial.distance import cdist
    
    # Extraer coordenadas de los nodos
    coords = []
    node_list = list(G.nodes())
    print(f"ğŸ“Š Voronoi procesando {len(node_list)} nodos")
    
    for node in node_list:
        if 'x' in G.nodes[node] and 'y' in G.nodes[node]:
            coords.append([G.nodes[node]['x'], G.nodes[node]['y']])
        else:
            coords.append([0, 0])
    
    coords = np.array(coords)
    print(f"ğŸ“ Voronoi: Coordenadas extraÃ­das, forma: {coords.shape}")
    
    if len(coords) < 2:
        print("âš ï¸ Voronoi: Muy pocos nodos, usando divisiÃ³n simple")
        mid = len(node_list) // 2
        part1 = set(node_list[:mid])
        part2 = set(node_list[mid:])
        return part1, part2
    
    # Encontrar dos puntos extremos como semillas de Voronoi
    print("ğŸ¯ Voronoi: Calculando matriz de distancias...")
    distances = cdist(coords, coords)
    i, j = np.unravel_index(distances.argmax(), distances.shape)
    
    seed1 = coords[i]
    seed2 = coords[j]
    max_distance = distances[i, j]
    
    print(f"ğŸŒ± Voronoi: Semillas seleccionadas - Seed1: {seed1}, Seed2: {seed2}")
    print(f"ğŸ“ Voronoi: Distancia mÃ¡xima entre semillas: {max_distance:.2f}")
    
    # Asignar cada nodo al centro mÃ¡s cercano (Voronoi)
    part1 = set()
    part2 = set()
    
    for idx, node in enumerate(node_list):
        coord = coords[idx]
        dist1 = np.linalg.norm(coord - seed1)
        dist2 = np.linalg.norm(coord - seed2)
        
        if dist1 <= dist2:
            part1.add(node)
        else:
            part2.add(node)
    
    print(f"âœ… Voronoi completado: RegiÃ³n 1 = {len(part1)} nodos, RegiÃ³n 2 = {len(part2)} nodos")
    
    return part1, part2

def split_graph_random(G):
    """DivisiÃ³n aleatoria pero balanceada de los nodos"""
    print("ğŸ”¥ EJECUTANDO ALGORITMO RANDOM REAL")
    import random
    
    node_list = list(G.nodes())
    print(f"ğŸ“Š Random procesando {len(node_list)} nodos")
    
    # Establecer semilla para reproducibilidad en logs
    random.seed(42)
    print("ğŸ² Random: Mezclando nodos aleatoriamente con semilla=42")
    random.shuffle(node_list)  # Mezclar aleatoriamente
    
    # Dividir aproximadamente por la mitad
    mid = len(node_list) // 2
    part1 = set(node_list[:mid])
    part2 = set(node_list[mid:])
    
    print(f"âœ… Random completado: Parte 1 = {len(part1)} nodos, Parte 2 = {len(part2)} nodos")
    print(f"ğŸ“ Random: DivisiÃ³n en Ã­ndice {mid} de {len(node_list)} nodos totales")
    
    return part1, part2

def split_graph_dbscan(G):
    """DivisiÃ³n usando DBSCAN clustering basado en densidad"""
    print("ğŸ”¥ EJECUTANDO ALGORITMO DBSCAN REAL")
    from sklearn.cluster import DBSCAN
    import numpy as np
    from sklearn.preprocessing import StandardScaler
    
    # Extraer coordenadas de los nodos
    coords = []
    node_list = list(G.nodes())
    print(f"ğŸ“Š DBSCAN procesando {len(node_list)} nodos")
    
    for node in node_list:
        if 'x' in G.nodes[node] and 'y' in G.nodes[node]:
            coords.append([G.nodes[node]['x'], G.nodes[node]['y']])
        else:
            # Si no hay coordenadas, usar posiciÃ³n por defecto
            coords.append([0, 0])
    
    coords = np.array(coords)
    print(f"ğŸ“ DBSCAN: Coordenadas extraÃ­das, forma: {coords.shape}")
    
    # Normalizar coordenadas para mejor rendimiento de DBSCAN
    scaler = StandardScaler()
    coords_scaled = scaler.fit_transform(coords)
    print(f"ğŸ“ DBSCAN: Coordenadas normalizadas")
    
    # Calcular eps automÃ¡ticamente basado en la densidad de datos
    from sklearn.neighbors import NearestNeighbors
    nbrs = NearestNeighbors(n_neighbors=min(5, len(coords_scaled))).fit(coords_scaled)
    distances, indices = nbrs.kneighbors(coords_scaled)
    eps = np.percentile(distances[:, -1], 75)  # 75th percentile
    min_samples = max(3, len(coords_scaled) // 20)  # Al menos 3, mÃ¡ximo 5% de datos
    
    print(f"ğŸ¯ DBSCAN: eps={eps:.4f}, min_samples={min_samples}")
    
    # Aplicar DBSCAN
    print("ğŸ¯ DBSCAN: Ejecutando clustering basado en densidad...")
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    labels = dbscan.fit_predict(coords_scaled)
    
    # Analizar resultados
    unique_labels = set(labels)
    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)
    n_noise = list(labels).count(-1)
    
    print(f"ğŸ“Š DBSCAN: {n_clusters} clusters detectados, {n_noise} puntos de ruido")
    
    # Si DBSCAN detecta mÃ¡s de 2 clusters, usar K-means como fallback
    if n_clusters > 2:
        print("âš ï¸ DBSCAN detectÃ³ mÃ¡s de 2 clusters, usando K-means como fallback")
        return split_graph_kmeans(G)
    
    # Si DBSCAN detecta solo 1 cluster, dividir manualmente
    if n_clusters == 1:
        print("âš ï¸ DBSCAN detectÃ³ solo 1 cluster, dividiendo manualmente")
        mid = len(node_list) // 2
        part1 = set(node_list[:mid])
        part2 = set(node_list[mid:])
    else:
        # Dividir nodos segÃºn las etiquetas de DBSCAN
        part1 = set()
        part2 = set()
        
        for i, node in enumerate(node_list):
            if labels[i] == 0:
                part1.add(node)
            elif labels[i] == 1:
                part2.add(node)
            else:
                # Puntos de ruido (-1) se asignan al cluster mÃ¡s cercano
                if len(part1) <= len(part2):
                    part1.add(node)
                else:
                    part2.add(node)
    
    print(f"âœ… DBSCAN completado: Cluster 1 = {len(part1)} nodos, Cluster 2 = {len(part2)} nodos")
    print(f"ğŸ“ˆ DBSCAN: Clusters detectados = {n_clusters}, Puntos de ruido = {n_noise}")
    
    return part1, part2

def split_graph_spectral(G):
    """DivisiÃ³n usando Spectral Clustering basado en conectividad"""
    print("ğŸ”¥ EJECUTANDO ALGORITMO SPECTRAL CLUSTERING REAL")
    from sklearn.cluster import SpectralClustering
    import numpy as np
    from sklearn.metrics.pairwise import rbf_kernel
    
    # Extraer coordenadas de los nodos
    coords = []
    node_list = list(G.nodes())
    print(f"ğŸ“Š Spectral Clustering procesando {len(node_list)} nodos")
    
    for node in node_list:
        if 'x' in G.nodes[node] and 'y' in G.nodes[node]:
            coords.append([G.nodes[node]['x'], G.nodes[node]['y']])
        else:
            # Si no hay coordenadas, usar posiciÃ³n por defecto
            coords.append([0, 0])
    
    coords = np.array(coords)
    print(f"ğŸ“ Spectral: Coordenadas extraÃ­das, forma: {coords.shape}")
    
    # Si hay muy pocos nodos, usar K-means como fallback
    if len(coords) < 10:
        print("âš ï¸ Spectral: Muy pocos nodos, usando K-means como fallback")
        return split_graph_kmeans(G)
    
    # Calcular matriz de similitud usando kernel RBF
    print("ğŸ¯ Spectral: Calculando matriz de similitud...")
    gamma = 1.0 / (coords.var() * coords.shape[1])  # ParÃ¡metro gamma automÃ¡tico
    affinity_matrix = rbf_kernel(coords, gamma=gamma)
    
    print(f"ğŸ“Š Spectral: Matriz de similitud calculada, gamma={gamma:.4f}")
    
    # Aplicar Spectral Clustering
    print("ğŸ¯ Spectral: Ejecutando clustering espectral...")
    spectral = SpectralClustering(
        n_clusters=2,
        affinity='precomputed',
        random_state=42,
        assign_labels='kmeans'
    )
    labels = spectral.fit_predict(affinity_matrix)
    
    # Dividir nodos segÃºn las etiquetas
    part1 = set()
    part2 = set()
    
    for i, node in enumerate(node_list):
        if labels[i] == 0:
            part1.add(node)
        else:
            part2.add(node)
    
    print(f"âœ… Spectral Clustering completado: Cluster 1 = {len(part1)} nodos, Cluster 2 = {len(part2)} nodos")
    print(f"ğŸ“ˆ Spectral: Eigenvalores calculados, clusters asignados")
    
    return part1, part2

def draw_partitioned_graph(G, part1, part2):
    print("Dibujando el grafo con zonas en rojo y azul...")
    color_map = ['red' if node in part1 else 'blue' for node in G.nodes()]
    nx.draw(G, node_color=color_map, node_size=10, edge_color='gray', with_labels=False)
    plt.show()

def calcular_longitud_por_zona(G, part1, part2):
    total_part1 = 0
    total_part2 = 0
    for u, v, data in G.edges(data=True):
        length = data.get("length", 0)
        if u in part1 and v in part1:
            total_part1 += length
        elif u in part2 and v in part2:
            total_part2 += length
    return total_part1, total_part2



def calcular_area_por_zona(G, part1, part2):
    def area_de_particion(nodos):
        puntos = [Point((G.nodes[n]['x'], G.nodes[n]['y'])) for n in nodos]
        gdf = gpd.GeoDataFrame(geometry=puntos, crs="EPSG:4326")
        gdf = gdf.to_crs(epsg=32614)  # UTM zona 14N
        union_geom = gdf.geometry.union_all()
        hull = union_geom.convex_hull
        return hull.area / 1_000_000 if hull.area else 0
    return area_de_particion(part1), area_de_particion(part2)

def generate_route_js(G, part1, part2):
    """Genera el JavaScript para las rutas del mapa"""
    js_lines = []
    
    # Generar rutas para zona 1 (roja)
    route1_segments = []
    for u, v, data in G.edges(data=True):
        if u in part1 and v in part1:
            if 'geometry' in data:
                coords = [[pt[1], pt[0]] for pt in data['geometry'].coords]  # [lat, lon] para Leaflet
            else:
                coords = [[G.nodes[u]['y'], G.nodes[u]['x']], [G.nodes[v]['y'], G.nodes[v]['x']]]
            route1_segments.append(coords)
    
    if route1_segments:
        js_lines.append("// Ruta zona 1 (roja)")
        for i, segment in enumerate(route1_segments):
            js_lines.append(f"L.polyline({segment}, {{color: 'red', weight: 3, opacity: 0.7}}).addTo(map);")
    
    # Generar rutas para zona 2 (azul)
    route2_segments = []
    for u, v, data in G.edges(data=True):
        if u in part2 and v in part2:
            if 'geometry' in data:
                coords = [[pt[1], pt[0]] for pt in data['geometry'].coords]  # [lat, lon] para Leaflet
            else:
                coords = [[G.nodes[u]['y'], G.nodes[u]['x']], [G.nodes[v]['y'], G.nodes[v]['x']]]
            route2_segments.append(coords)
    
    if route2_segments:
        js_lines.append("// Ruta zona 2 (azul)")
        for i, segment in enumerate(route2_segments):
            js_lines.append(f"L.polyline({segment}, {{color: 'blue', weight: 3, opacity: 0.7}}).addTo(map);")
    
    return "\n        ".join(js_lines)

def draw_graph_folium(G, part1, part2, place_name="colonia", output_html=None):
    print("Generando mapa interactivo con folium...")
    base_mapa_dir = Path(__file__).resolve().parent.parent / "mapas_division"
    base_mapa_dir.mkdir(parents=True, exist_ok=True)
    filename = output_html or f"mapa_{sanitize_filename(place_name)}.html"
    nombre_archivo = base_mapa_dir / filename

    centro = list(G.nodes(data=True))[0][1]
    m = folium.Map(location=[centro['y'], centro['x']], zoom_start=16)

    # Dibujar calles respetando la geometrÃ­a real
    for u, v, data in G.edges(data=True):
        if 'geometry' in data:
            coords = [(pt[1], pt[0]) for pt in data['geometry'].coords]
        else:
            coords = [(G.nodes[u]['y'], G.nodes[u]['x']), (G.nodes[v]['y'], G.nodes[v]['x'])]

        # Colorear calles segÃºn la zona
        if u in part1 and v in part1:
            color = 'red'
        elif u in part2 and v in part2:
            color = 'blue'
        else:
            color = 'gray'

        folium.PolyLine(coords, color=color, weight=3, opacity=0.7).add_to(m)

    # Guardar el archivo HTML
    m.save(nombre_archivo)
    
    # Leer el contenido HTML generado y optimizarlo para la base de datos
    with open(nombre_archivo, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    # Crear una versiÃ³n optimizada del HTML para la base de datos
    # Extraer solo la parte del mapa sin las dependencias externas
    optimized_html = f"""
    <div class="folium-map" id="map_{sanitize_filename(place_name)}" style="width: 100%; height: 400px;"></div>
    <script>
        // Inicializar mapa
        var map = L.map("map_{sanitize_filename(place_name)}", {{
            center: [{centro['y']}, {centro['x']}],
            zoom: 16,
            crs: L.CRS.EPSG3857
        }});
        
        // Agregar capa de tiles
        L.tileLayer("https://tile.openstreetmap.org/{{z}}/{{x}}/{{y}}.png", {{
            attribution: "Â© OpenStreetMap contributors",
            maxZoom: 19
        }}).addTo(map);
        
        // Agregar rutas
        {generate_route_js(G, part1, part2)}
    </script>
    """
    
    return {
        'file_path': os.path.abspath(nombre_archivo),
        'html_content': optimized_html
    }


from osmnx.distance import add_edge_lengths

def procesar_poligono_completo(colonia_id: int, num_employees=2, algorithm='kernighan_lin'):
    """
    Procesa un polÃ­gono usando datos de la base de datos en lugar de archivos fÃ­sicos
    """
    print("ğŸ¯" + "=" * 70)
    print(f"ğŸŒŸ PROCESAMIENTO COMPLETO DE POLÃGONO INICIADO")
    print(f"ğŸ†” Colonia ID: {colonia_id}")
    print(f"ğŸ‘¥ Empleados: {num_employees}")
    print(f"ğŸ”§ Algoritmo: {algorithm}")
    print("ğŸ¯" + "=" * 70)
    
    # Importar modelos de Django
    try:
        from core.models import ColoniaProcesada
    except ImportError:
        print("âŒ Error importing Django models")
        raise
    
    try:
        print(f"ğŸ” Buscando colonia con ID: {colonia_id}")
        colonia = ColoniaProcesada.objects.get(id=colonia_id)
        print(f"âœ… Colonia encontrada: {colonia.nombre}")
        
        if not colonia.poligono_geojson:
            print(f"âŒ POLÃGONO NO ENCONTRADO en la base de datos para: {colonia.nombre}")
            raise FileNotFoundError(f"No se encontrÃ³ polÃ­gono GeoJSON para la colonia: {colonia.nombre}")
        
        print(f"âœ… PolÃ­gono GeoJSON encontrado en base de datos")
        geojson = colonia.poligono_geojson
        
    except ColoniaProcesada.DoesNotExist:
        print(f"âŒ COLONIA NO ENCONTRADA con ID: {colonia_id}")
        raise FileNotFoundError(f"No se encontrÃ³ la colonia con ID: {colonia_id}")

    print(f"ğŸ—ºï¸ Convirtiendo geometrÃ­a y descargando grafo de calles...")
    geometry = shape(geojson["geometry"])
    G = ox.graph_from_polygon(geometry, network_type='walk')
    G = add_edge_lengths(G)
    G = nx.Graph(G)  # convertir a grafo no dirigido

    print(f"ğŸ—ï¸ Grafo construido: {len(G.nodes())} nodos, {len(G.edges())} aristas")
    print(f"ğŸš€ Iniciando divisiÃ³n con algoritmo '{algorithm}'...")

    part1, part2 = split_graph(G, num_employees, algorithm)
    
    # Calcular Silhouette Score
    silhouette_score = calcular_silhouette_score(G, part1, part2)
    
    long1, long2 = calcular_longitud_por_zona(G, part1, part2)
    area1, area2 = calcular_area_por_zona(G, part1, part2)

    dens_nodos1 = len(part1) / area1 if area1 else 0
    dens_nodos2 = len(part2) / area2 if area2 else 0
    dens_calles1 = long1 / area1 if area1 else 0
    dens_calles2 = long2 / area2 if area2 else 0

    mapa_result = draw_graph_folium(G, part1, part2, place_name=f"colonia_{colonia_id}")


       
       # EstadÃ­sticas de nodos
    print(f"ğŸ“Š Total de nodos: {len(G.nodes)}")
    print(f"ğŸ”´ Zona 1 (vendedor A): {len(part1)} nodos")
    print(f"ğŸ”µ Zona 2 (vendedor B): {len(part2)} nodos")

    # EstadÃ­sticas de longitud
    print(f"ğŸ›£ï¸ Longitud total zona 1 (rojo): {long1:.2f} m")
    print(f"ğŸ›£ï¸ Longitud total zona 2 (azul): {long2:.2f} m")
    
    
    print(f"ğŸ“ Ãrea zona 1 (rojo): {area1:.2f} mÂ²")
    print(f"ğŸ“ Ãrea zona 2 (azul): {area2:.2f} mÂ²")
    
   
    print(f"ğŸ”— Densidad de nodos zona 1: {dens_nodos1:.2f} nodos/kmÂ²")
    print(f"ğŸ”— Densidad de nodos zona 2: {dens_nodos2:.2f} nodos/kmÂ²")
    print(f"ğŸš Densidad de calles zona 1: {dens_calles1:.2f} m/kmÂ²")
    print(f"ğŸš Densidad de calles zona 2: {dens_calles2:.2f} m/kmÂ²")

    return {
        "status": "ok",
        "mapa_html": mapa_result['file_path'],
        "mapa_html_content": mapa_result['html_content'],
        "nodos": {
            "zona1": len(part1),
            "zona2": len(part2),
            "total": len(G.nodes),
        },
        "longitudes": {
            "zona1_m": round(long1, 2),
            "zona2_m": round(long2, 2)
        },
        "areas": {
            "zona1_m2": round(area1, 2),
            "zona2_m2": round(area2, 2)
        },
        "densidades": {
            "nodos_por_km2_z1": round(dens_nodos1, 2),
            "nodos_por_km2_z2": round(dens_nodos2, 2),
            "calles_m_por_km2_z1": round(dens_calles1, 2),
            "calles_m_por_km2_z2": round(dens_calles2, 2)
        },
        "silhouette_score": silhouette_score,
        "part1_nodes": part1,
        "part2_nodes": part2,
        "graph": G
    }


def calcular_silhouette_score(G, part1, part2):
    """
    Calcula el Silhouette Score para evaluar la calidad del clustering de nodos.
    
    Args:
        G: NetworkX graph
        part1: set de nodos de la zona 1
        part2: set de nodos de la zona 2
    
    Returns:
        float: Silhouette Score entre -1 y 1
    """
    try:
        from sklearn.metrics import silhouette_score
        import numpy as np
        
        print("ğŸ¯ CALCULANDO SILHOUETTE SCORE...")
        
        # Si solo hay una zona, el score es perfecto
        if len(part1) == 0 or len(part2) == 0:
            print("âœ… Una sola zona detectada - Silhouette Score = 1.0")
            return 1.0
        
        # Extraer coordenadas de todos los nodos
        coords = []
        labels = []
        node_list = list(G.nodes())
        
        for node in node_list:
            if 'x' in G.nodes[node] and 'y' in G.nodes[node]:
                coords.append([G.nodes[node]['x'], G.nodes[node]['y']])
                if node in part1:
                    labels.append(0)  # Zona 1
                elif node in part2:
                    labels.append(1)  # Zona 2
                else:
                    # Nodos no asignados (no deberÃ­a pasar)
                    labels.append(-1)
            else:
                print(f"âš ï¸ Nodo {node} sin coordenadas, usando [0,0]")
                coords.append([0, 0])
                if node in part1:
                    labels.append(0)
                elif node in part2:
                    labels.append(1)
                else:
                    labels.append(-1)
        
        coords = np.array(coords)
        labels = np.array(labels)
        
        # Filtrar nodos vÃ¡lidos (asignados a alguna zona)
        valid_mask = labels != -1
        if not np.any(valid_mask):
            print("âŒ No hay nodos vÃ¡lidos para calcular Silhouette Score")
            return 0.0
        
        coords_valid = coords[valid_mask]
        labels_valid = labels[valid_mask]
        
        # Verificar que tenemos al menos 2 clusters y mÃºltiples puntos
        unique_labels = np.unique(labels_valid)
        if len(unique_labels) < 2:
            print("âŒ Solo hay un cluster - Silhouette Score = 1.0")
            return 1.0
        
        if len(coords_valid) < 3:
            print("âŒ Muy pocos puntos para calcular Silhouette Score")
            return 0.0
        
        # Calcular Silhouette Score
        try:
            score = silhouette_score(coords_valid, labels_valid, metric='euclidean')
            print(f"âœ… Silhouette Score calculado: {score:.4f}")
            
            # InterpretaciÃ³n del score
            if score >= 0.7:
                interpretacion = "Excelente clustering"
            elif score >= 0.5:
                interpretacion = "Buen clustering"
            elif score >= 0.25:
                interpretacion = "Clustering aceptable"
            elif score >= 0:
                interpretacion = "Clustering dÃ©bil"
            else:
                interpretacion = "Clustering incorrecto"
            
            print(f"ğŸ“Š InterpretaciÃ³n: {interpretacion}")
            return round(score, 4)
            
        except Exception as e:
            print(f"âŒ Error calculando Silhouette Score: {str(e)}")
            return 0.0
            
    except ImportError:
        print("âŒ sklearn no disponible - usando score estimado")
        return 0.75  # Score estimado conservador
    except Exception as e:
        print(f"âŒ Error general en cÃ¡lculo de Silhouette Score: {str(e)}")
        return 0.0
